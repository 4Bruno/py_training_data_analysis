{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ca6ece8-950f-4c95-bcaf-ce4830e96936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "efbb601c-b3e7-4e7c-ac63-e728e40fd86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_sources = os.path.abspath(os.path.join(os.getcwd(),'data_analyst','Resources','Data'))\n",
    "data_source = 'Lending-company-Numeric.csv'\n",
    "data_source_nan = 'Lending-company-Numeric-NAN.csv'\n",
    "data_source_mixed = 'Lending-Company-Saving.csv'\n",
    "data = []\n",
    "data_nan = []\n",
    "data_mixed = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d049a3d1-ce8d-4333-806f-7bbbb801c720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sources():\n",
    "    global data\n",
    "    global data_nan\n",
    "    global data_mixed\n",
    "    data = np.loadtxt(os.path.join(dir_sources,data_source),delimiter=',')\n",
    "    data_nan = np.genfromtxt(os.path.join(dir_sources,data_source_nan),delimiter=';')\n",
    "    data_mixed = np.genfromtxt(os.path.join(dir_sources,data_source_mixed),delimiter=',',dtype=str)\n",
    "load_sources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abf7fbec-8cc6-4d88-8893-aae6d2b833ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean file has 0 nan\n",
      "Not clean file has 260 nan\n"
     ]
    }
   ],
   "source": [
    "data_has_nan = np.isnan(data).sum()\n",
    "data_nan_has_nan = np.isnan(data_nan).sum()\n",
    "print(f'Clean file has {data_has_nan} nan')\n",
    "print(f'Not clean file has {data_nan_has_nan} nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f18cd510-4506-4cb2-8d84-c1c26dd989da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can 'fix' NaN by filling with 0\n",
    "data_nan = np.genfromtxt(os.path.join(dir_sources,data_source_nan),delimiter=';',filling_values = 0)\n",
    "np.isnan(data_nan).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6f4652b-22f5-42e4-a7b5-d317988312c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN found after filling 0\n",
      "--------------------------------------------------------------------------------------------\n",
      "np.nanmean of dataset column 0 -> 2250.25\n",
      "4263.25 this is the value of distorted mean\n",
      "2250.25 this is the value after replacing the values for the actual mean\n",
      "--------------------------------------------------------------------------------------------\n",
      "For column 0 does it match? True\n",
      "For column 1 does it match? True\n",
      "For column 2 does it match? True\n",
      "For column 3 does it match? True\n",
      "For column 4 does it match? True\n",
      "For column 5 does it match? True\n"
     ]
    }
   ],
   "source": [
    "# The above strategy fails apart if the dataset happens to have 0s.\n",
    "# Instead we can use an arbitrary number (for instance the highest value in dataset + 1)\n",
    "# For that, first we load data without filling\n",
    "data_nan = np.genfromtxt(os.path.join(dir_sources,data_source_nan),delimiter=';')\n",
    "# remember we need to use nan version of max to handle nan values\n",
    "data_nan_maxval_plus_one = np.nanmax(data_nan).round(2) + 1\n",
    "# storage the mean of each column\n",
    "temporary_mean = np.nanmean(data_nan,axis=0).round(2)\n",
    "# re-open the data filling with the arbitrary number\n",
    "data_nan = np.genfromtxt(os.path.join(dir_sources,data_source_nan),delimiter=';', filling_values=data_nan_maxval_plus_one)\n",
    "print(f'Number of NaN found after filling {np.isnan(data_nan).sum()}')\n",
    "print('--------------------------------------------------------------------------------------------')\n",
    "# Now, by filling NaN values we are distorting the calculations (mean,avg, std, ...)\n",
    "print(f'np.nanmean of dataset column 0 -> {temporary_mean[0]}')\n",
    "print(f'{np.mean(data_nan[:,0]).round(2)} this is the value of distorted mean')\n",
    "# How to fix it?\n",
    "data_nan[:,0] = np.where(data_nan[:,0] == data_nan_maxval_plus_one,\n",
    "                          temporary_mean[0],\n",
    "                         data_nan[:,0])\n",
    "print(f'{np.mean(data_nan[:,0]).round(2)} this is the value after replacing the values for the actual mean')\n",
    "print('--------------------------------------------------------------------------------------------')\n",
    "# Now we want to do the same for each column\n",
    "for c in range(data_nan.shape[1]):\n",
    "    data_nan[:,c] = np.where(data_nan[:,c] == data_nan_maxval_plus_one, temporary_mean[c], data_nan[:,c])\n",
    "    # Now check against the mean\n",
    "    print(f'For column {c} does it match? {np.mean(data_nan[:,c]).round(2) == temporary_mean[c]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbc3a929-2f1a-4058-a872-ba8b115f5429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 447)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_divisors(X):\n",
    "    divisors = []\n",
    "    for i in range(1, X + 1):\n",
    "        if X % i == 0:\n",
    "            divisors.append(i)\n",
    "    return divisors\n",
    "\n",
    "# re-shaping\n",
    "# very particular cases when you want to wrap/unwrap the rows\n",
    "# rows/cols size can't be random, it has to follow a logical wrap\n",
    "total_size = (data_nan.shape[0] * data_nan.shape[1])\n",
    "# pick an arbitrary divisor\n",
    "arbitrary_divisor = 5\n",
    "divisor = find_divisors(total_size)[arbitrary_divisor]\n",
    "new_shape_rows= divisor\n",
    "new_shape_cols= int(total_size / divisor)\n",
    "data_reshape = np.reshape(data_nan,newshape=(new_shape_rows, new_shape_cols))\n",
    "data_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0d91dd6-518b-4cdc-b2dc-52e041e19d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1043, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1043, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete data\n",
    "print(data_nan.shape)\n",
    "np.delete(data_nan, np.s_[::2],axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8abecf68-3892-4d2a-a751-0ebda3aa4666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1000.    35.   365. -2870. -2870.  -350.]\n",
      " [ 1000.    35.   365. -2550. -2100.  1100.]\n",
      " [ 1000.    35.   365. -2450. -1750.  1160.]\n",
      " ...\n",
      " [ 9000.   125.   365. 16001. 18250. 54625.]\n",
      " [ 9000.   165.   365. 16751. 18751. 54625.]\n",
      " [ 9000.   165.   365. 17650. 20001. 64001.]]\n",
      "[[   40.     365.    2000.    3121.    4241.   13621.  ]\n",
      " [   40.     365.    2000.    3061.    4171.   15041.  ]\n",
      " [   40.     365.    1000.    2160.    3280.   15340.  ]\n",
      " ...\n",
      " [   40.     365.    2250.25  4201.    5001.   16600.  ]\n",
      " [   40.     365.    1000.    2080.    3320.   15600.  ]\n",
      " [   40.     365.    2000.    4601.    4601.   16600.  ]]\n",
      "[[13621.    4241.    3121.    2000.     365.      40.  ]\n",
      " [15041.    4171.    3061.    2000.     365.      40.  ]\n",
      " [15340.    3280.    2160.    1000.     365.      40.  ]\n",
      " ...\n",
      " [16600.    5001.    4201.    2250.25   365.      40.  ]\n",
      " [15600.    3320.    2080.    1000.     365.      40.  ]\n",
      " [16600.    4601.    4601.    2000.     365.      40.  ]]\n"
     ]
    }
   ],
   "source": [
    "# sorting rows/columns independently\n",
    "# set option to not display cientific notation (AKA: 000e+0X)\n",
    "np.set_printoptions(suppress = True)\n",
    "# Notice this is treating each column/row individually and sorting them\n",
    "# to sort as a database table use np.argsort or np.lexsort (multi-col)\n",
    "data_sorted_by_col = np.sort(data_nan,axis=0)\n",
    "data_sorted_by_row = np.sort(data_nan,axis=1)\n",
    "# in order to switch between asc -> desc order, we can add '-' to the operation as in:\n",
    "# notice there are 2 '-' signs. -data_nan inverts sign of every element in the matrix\n",
    "# the outer '-' (-np.sort), reverts it\n",
    "data_sorted_by_row_desc = -np.sort(-data_nan,axis=1)\n",
    "print(data_sorted_by_col)\n",
    "print(data_sorted_by_row)\n",
    "print(data_sorted_by_row_desc)\n",
    "# if you need to save the sorting output\n",
    "# either assign it to new var or use the .sort method on the matrix directly\n",
    "# data_nan.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3afb14e6-70a0-4478-88ea-59a2bdadad49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Anthony' '5' '8']\n",
      " ['Julia' '8' '5']\n",
      " ['Julia' '2' '3']\n",
      " ['Ramon' '4' '9']\n",
      " ['Ramon' '2' '7']]\n",
      "[0 4 3 2 1]\n",
      "[['Anthony' '5' '8']\n",
      " ['Julia' '2' '3']\n",
      " ['Julia' '8' '5']\n",
      " ['Ramon' '2' '7']\n",
      " ['Ramon' '4' '9']]\n"
     ]
    }
   ],
   "source": [
    "# Sorting matrices as dependent datasets (AKA tables)\n",
    "# Very important to remember!\n",
    "# np.lexsort can take a tuple (m[:,0],m[:,1]) for the sorting arg\n",
    "# but keep in mind the sorting order is reversed\n",
    "# you need to insert in order from LAST to FIRST\n",
    "# in the following sample if we want to sort by NAME then by RATE\n",
    "# the tuple should be passed as (RATE, NAME)\n",
    "sample = np.array([['Anthony',5,8],\n",
    "                  ['Ramon', 4,9],\n",
    "                  ['Ramon', 2,7],\n",
    "                  ['Julia',8,5],\n",
    "                  ['Julia',2,3]])\n",
    "sorted_index_by_name = np.argsort(sample[:,0],axis=0)\n",
    "sample_with_index_by_name = sample.copy()[sorted_index_by_name]\n",
    "print(sample_with_index_by_name)\n",
    "sorted_index_by_name_and_rate = np.lexsort((sample[:,1],sample[:,0]),axis=0)\n",
    "sample_with_index_by_name_and_rate = sample.copy()[sorted_index_by_name_and_rate]\n",
    "print(sorted_index_by_name_and_rate)\n",
    "print(sample_with_index_by_name_and_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "92f5120f-81a1-4ff7-b187-c9141711ae59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices_column_name_matching < 'Elisa'\n",
      "[[0]]\n",
      "indices_any_matching < 'Elisa'\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 1]\n",
      " [1 2]\n",
      " [2 1]\n",
      " [2 2]\n",
      " [3 1]\n",
      " [3 2]\n",
      " [4 1]\n",
      " [4 2]]\n"
     ]
    }
   ],
   "source": [
    "# np.argwhere()\n",
    "# Checks elements against a condition\n",
    "# Returns array ONLY with the indexes of elements matching the condition\n",
    "sample = np.array([['Anthony',5,8],\n",
    "                  ['Ramon', 4,9],\n",
    "                  ['Ramon', 2,7],\n",
    "                  ['Julia',8,5],\n",
    "                  ['Julia',2,3]])\n",
    "arg = \"< 'Elisa'\"\n",
    "indices_column_name_matching = eval('np.argwhere(sample[:,0] ' + arg + ')')\n",
    "print('indices_column_name_matching ' + arg)\n",
    "print(indices_column_name_matching)\n",
    "indices_any_matching = eval('np.argwhere(sample ' + arg + ')')\n",
    "print('indices_any_matching ' + arg)\n",
    "print(indices_any_matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e4b2dfee-6219-4da7-982e-04960dd25bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261 values as NaN found\n",
      "261 indices of NaN values\n",
      "0 indices of NaN values after replace\n"
     ]
    }
   ],
   "source": [
    "# np.argwhere interesting interactions\n",
    "load_sources()\n",
    "# we have NaN values in our dataset\n",
    "count_nan = np.isnan(data_nan).sum()\n",
    "print(f'{count_nan} values as NaN found')\n",
    "# we can find all positions\n",
    "indices_nan = np.argwhere(np.isnan(data_nan))\n",
    "print(f'{indices_nan.shape[0]} indices of NaN values')\n",
    "# now we can loop through all indices and do something\n",
    "for ind in indices_nan:\n",
    "    data_nan[ind[0],ind[1]] = 0\n",
    "indices_nan = np.argwhere(np.isnan(data_nan))\n",
    "print(f'{indices_nan.shape[0]} indices of NaN values after replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d500751c-befc-4200-92ce-a6d805b693b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2000.    40.   365.  3121.  4241. 13621.]\n",
      " [ 2000.    40.   365.  3061.  4171. 15041.]\n",
      " [ 1000.    40.   365.  2160.  3280. 15340.]\n",
      " [ 2000.    40.   365.  3041.  4241. 15321.]]\n",
      "After shuffling\n",
      "[[ 2000.    40.   365.  3121.  4241. 13621.]\n",
      " [ 1000.    40.   365.  2160.  3280. 15340.]\n",
      " [ 2000.    40.   365.  3061.  4171. 15041.]\n",
      " [ 2000.    40.   365.  3041.  4241. 15321.]]\n",
      "After shuffling\n",
      "[[ 2000.    40.   365.  3061.  4171. 15041.]\n",
      " [ 1000.    40.   365.  2160.  3280. 15340.]\n",
      " [ 2000.    40.   365.  3121.  4241. 13621.]\n",
      " [ 2000.    40.   365.  3041.  4241. 15321.]]\n"
     ]
    }
   ],
   "source": [
    "# shuffling\n",
    "# contrary to most of the functions, shuffle is IN PLACE method\n",
    "# meaning you won't get back a copy, it modifies the passed array\n",
    "data_limited = data[:4,:].copy()\n",
    "print(data_limited)\n",
    "np.random.shuffle(data_limited)\n",
    "print('After shuffling')\n",
    "print(data_limited)\n",
    "# In theory, we should use the generator lib\n",
    "from numpy.random import Generator as gen\n",
    "from numpy.random import PCG64 as pcg\n",
    "# -----------------------------\n",
    "# IMPORTANT!\n",
    "# seed doesn't have any effect on shuffle\n",
    "# -----------------------------\n",
    "rnd_gen = gen(pcg())\n",
    "rnd_gen.shuffle(data_limited)\n",
    "print('After shuffling')\n",
    "print(data_limited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d031ad5f-be5d-4497-b5fa-ba25b8f708bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2000.    40.   365.  3121.  4241. 13621.]\n",
      " [ 2000.    40.   365.  3061.  4171. 15041.]\n",
      " [ 1000.    40.   365.  2160.  3280. 15340.]\n",
      " [ 2000.    40.   365.  3041.  4241. 15321.]]\n",
      "[['2000.0' '40.0' '365.0' '3121.0' '4241.0' '13621.0']\n",
      " ['2000.0' '40.0' '365.0' '3061.0' '4171.0' '15041.0']\n",
      " ['1000.0' '40.0' '365.0' '2160.0' '3280.0' '15340.0']\n",
      " ['2000.0' '40.0' '365.0' '3041.0' '4241.0' '15321.0']]\n",
      "[[ 2000    40   365  3121  4241 13621]\n",
      " [ 2000    40   365  3061  4171 15041]\n",
      " [ 1000    40   365  2160  3280 15340]\n",
      " [ 2000    40   365  3041  4241 15321]]\n"
     ]
    }
   ],
   "source": [
    "# casting, you need to assign to new variable to keep changes\n",
    "data_limited = data[:4,:].copy()\n",
    "print(data_limited)\n",
    "data_limited = data_limited.astype(dtype= str)\n",
    "print(data_limited)\n",
    "# casting directly from str -> int might not be possible in cases with '.'\n",
    "# we need to do double cast:\n",
    "# str -> float -> int\n",
    "# remove below comment line to throw error\n",
    "#data_limited = data_limited.astype(dtype= 'int')\n",
    "data_limited = data_limited.astype(dtype= 'float').astype(dtype='int')\n",
    "print(data_limited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b293ba21-56a9-4058-a2fc-7019cb2a4be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Product B' 'Location 2' 'Region 2']\n",
      " ['Product B' 'Location 3' '']\n",
      " ['Product C' 'Location 5' 'Region 5']\n",
      " ...\n",
      " ['Product B' 'Location 23' 'Region 4']\n",
      " ['Product C' 'Location 52' 'Region 6']\n",
      " ['Product B' 'Location 142' 'Region 6']]\n",
      "Removing leading strings\n",
      "[['B' '2' '2']\n",
      " ['B' '3' '']\n",
      " ['C' '5' '5']\n",
      " ...\n",
      " ['B' '23' '4']\n",
      " ['C' '52' '6']\n",
      " ['B' '142' '6']]\n",
      "Substituying products codes for numbers\n",
      "[['2' '2' '2']\n",
      " ['2' '3' '']\n",
      " ['3' '5' '5']\n",
      " ...\n",
      " ['2' '23' '4']\n",
      " ['3' '52' '6']\n",
      " ['2' '142' '6']]\n",
      "Non integers found? (Double check we covered all possible product letters)\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# string manipulation\n",
    "data_str = data_mixed[1:,[2,4,5]].copy()\n",
    "print(data_str)\n",
    "# clean up leading text\n",
    "data_clean_1 = np.chararray.strip(data_str,['Product ','Location ','Region '])\n",
    "print(\"Removing leading strings\")\n",
    "print(data_clean_1)\n",
    "# substitute product (A,B,C) for numbers\n",
    "# np.where can do the trick but is not very clean (visually)\n",
    "conditions = [data_clean_1[:,0] == 'A',\n",
    "              data_clean_1[:,0] == 'B',\n",
    "              data_clean_1[:,0] == 'C',\n",
    "              data_clean_1[:,0] == 'D',\n",
    "              data_clean_1[:,0] == 'E',\n",
    "              data_clean_1[:,0] == 'F',\n",
    "             ]\n",
    "values = [1, 2, 3,4, 5, 6]\n",
    "data_clean_1[:,0] = np.select(conditions, values,data_clean_1[:,0])\n",
    "print(\"Substituying products codes for numbers\")\n",
    "print(data_clean_1)\n",
    "non_digit_indeces = np.argwhere(~np.chararray.isdigit(data_clean_1[:,0]))\n",
    "print(\"Non integers found? (Double check we covered all possible product letters)\")\n",
    "print(non_digit_indeces.flatten())\n",
    "if non_digit_indeces.size > 0:\n",
    "    print(data_clean_1[:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "97f4b667-f572-42d8-b69e-4939b02bf856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertical stack\n",
      "[['Anthony' '5' '8']\n",
      " ['Ramon' '4' '9']\n",
      " ['Ramon' '2' '7']\n",
      " ['Julia' '8' '5']\n",
      " ['Julia' '2' '3']\n",
      " ['Anthony' '5' '8']\n",
      " ['Ramon' '4' '9']\n",
      " ['Ramon' '2' '7']\n",
      " ['Julia' '8' '5']\n",
      " ['Julia' '2' '3']]\n",
      "Horizontal stack\n",
      "[['Anthony' '5' '8' 'Anthony' '5' '8']\n",
      " ['Ramon' '4' '9' 'Ramon' '4' '9']\n",
      " ['Ramon' '2' '7' 'Ramon' '2' '7']\n",
      " ['Julia' '8' '5' 'Julia' '8' '5']\n",
      " ['Julia' '2' '3' 'Julia' '2' '3']]\n"
     ]
    }
   ],
   "source": [
    "# stacking\n",
    "sample = np.array([['Anthony',5,8],\n",
    "                  ['Ramon', 4,9],\n",
    "                  ['Ramon', 2,7],\n",
    "                  ['Julia',8,5],\n",
    "                  ['Julia',2,3]])\n",
    "# raw stack adds 1 dimension\n",
    "np.stack( (sample,sample), axis = 0 )\n",
    "# for 'traditional' stacking use alternatives\n",
    "stack_v = np.vstack( (sample,sample))\n",
    "stack_h = np.hstack( (sample,sample))\n",
    "print('Vertical stack')\n",
    "print(stack_v)\n",
    "print('Horizontal stack')\n",
    "print(stack_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b33fffb-cfb5-493e-bf9d-0585169cd47e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
